defaults:
  # presets do not directly configs the pipeline or the algothm. However it provides necessary information to resolve this config
  - preset_robomimic: lift_image 
  - _self_

batch_size: 128
seed: 43
debugrun: false
wandb_cfg:
  project: robomimic
  run_name: ${now:%Y%m%d-%H%M%S}_${.project}
  tags: ["robomimic", "${preset_robomimic.task_tag}", "diffusion_policy"]
  mode: "online"
output_dir: runs/${wandb_cfg.run_name}

pipeline:
  _target_: srl_il.pipeline.imitation_learning.ImitationLearningPipeline

dataset_cfg:
  data:
    _target_: srl_il.dataset.robomimic_dataset.robomimic_train_val_test
    data_path: ${preset_robomimic.data.data_path}
    rgb_processing_keys: ${preset_robomimic.data.rgb_processing_keys}
    preloaded: ${preset_robomimic.data.preloaded} # preload means to keep the data in memory, but some dataset may be too large for this
    test_fraction: 0.1
    val_fraction: 0.1
    window_size_train: 20 
    window_size_test: 20
    keys_traj: ${preset_robomimic.data.keys_traj}
    keys_global: []
    pad_before: false
    pad_after: true
    pad_type: 'near'
    random_seed: ${seed}
  batch_size: ${batch_size}
  pin_memory: true
  num_workers: ${preset_robomimic.data.num_worker} # we don't need a seperate worker if the data is preloaded


algo_cfg:
  _target_: srl_il.algo.diffusion_policy.DiffusionPolicyTrainer
  algo_cfg:
    device: cuda
    target_dims: ${preset_robomimic.target_dims}
    T_target: 20
    network_is_causal: false
    network_group_keys: ['low_dim', 'img0', 'img1']
    network_cfg:
      d_model: 256
      nhead: 8
      num_encoder_layers: 3
      dim_feedforward: 1024
      dropout: 0.1
      activation: 'relu'
    scheduler_cfg:
      num_train_timesteps: 100
      num_inference_steps: 100
      beta_schedule: squaredcos_cap_v2
      variance_type: fixed_small
      clip_sample: True
      beta_start: 0.0001
      beta_end: 0.02
  trainer_cfg:
    loss_params: null # diffusion policy only use l2 loss
    optimizer_cfg:
      network:
        optm_cls: torch.optim.Adam
        lr: 0.0001
      obs_encoder:
        optm_cls: torch.optim.Adam
        lr: 0.0001
      projs:
        optm_cls: torch.optim.Adam
        lr: 0.0001
      embeds:
        optm_cls: torch.optim.Adam
        lr: 0.0001

  obs_encoder_cfg:
    output_dim: 256
    obs_groups_cfg:
      low_dim:
        datakeys: ['robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']
        encoder_cfg:
          type: lowdim_concat
          input_dim_total: 9 # 3 + 4 + 2 
        posemb_cfg:
          type: none
      img0:
        datakeys: ['img0']
        encoder_cfg:
          type: resnet18 # crop_resnet18
          pretrained: true
        posemb_cfg:
          type: none
      img1:
        datakeys: ['img1']
        encoder_cfg:
          type: resnet18 # crop_resnet18
          pretrained: true
        posemb_cfg:
          type: none
    group_emb_cfg:
      type: none # none, whole_seq_sine, each_group_learned, whole_seq_learned

  policy_cfg: 
    policy_bs: 1
    policy_translator: 
      ## the following translator is used for relative action
      _target_: srl_il.algo.base_algo.PolicyTranslatorDirect
      ## the following translator is used for absolute action
      # _target_: srl_il.algo.base_algo.PolicyTranslator_6Drotation2Ang
      # action_name: actions
    policy_aggregator_cfg:
      type: "simple"
      update_every: 10

    policy_obs_list: # policy names and temporal length
      - ['robot0_eef_pos', 1]
      - ['robot0_eef_quat', 1]
      - ['robot0_gripper_qpos', 1]
      - ['img0', 1] 
      - ['img1', 1]
lr_scheduler_cfg:
  network:
    type: "diffusers"
    name: cosine
    params:
      num_warmup_steps: 200
      num_training_steps: 800000 # number per epoch * num_epochs
    step_with_metrics: false
  obs_encoder:
    type: "diffusers"
    name: cosine
    params:
      num_warmup_steps: 1000
      num_training_steps: 800000 # number per epoch * num_epochs
    step_with_metrics: false


training_cfg:
  num_epochs: ${preset_robomimic.train.num_epochs} 
  num_steps_per_epoch: 200
  num_eval_steps_per_epoch: 20
  steps_saving: 10
  rollout:
    every_n_epoch: 20
    enabled: true
    num_episodes: 10
    horizon: ${preset_robomimic.train.rollout_horizon}
    terminate_on_success: true
    video:
      video_dir: ${output_dir}/video
      video_skip: 5


normalizer_cfg:
  actions: # the target to reconstruct
    type: dataset_stats
    min_max: true
    dataname: actions
  robot0_eef_pos:
    type: dataset_stats
    dataname: robot0_eef_pos
  robot0_eef_quat:
    type: hardcode
    mean: 0.0
    std: 1.0
  robot0_gripper_qpos:
    type: dataset_stats
    dataname: robot0_gripper_qpos
  img0: # image net norm mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    type: hardcode
    mean: [[[0.485]], [[0.456]], [[0.406]]]
    std: [[[0.229]], [[0.224]], [[0.225]]]
  img1:
    type: hardcode
    mean: [[[0.485]], [[0.456]], [[0.406]]]
    std: [[[0.229]], [[0.224]], [[0.225]]]
  img2:
    type: hardcode
    mean: [[[0.485]], [[0.456]], [[0.406]]]
    std: [[[0.229]], [[0.224]], [[0.225]]]
  img3:
    type: hardcode
    mean: [[[0.485]], [[0.456]], [[0.406]]]
    std: [[[0.229]], [[0.224]], [[0.225]]]

data_augmentation_cfg: # data augmetation is only used for the data loaded from dataset, no simulation data augmentation
  data_augments:
    - outname: robot0_eef_pos
      type: gaussian_noise
      mean: 0.0
      std: 0.001
    - outname: robot0_gripper_qpos
      type: gaussian_noise
      mean: 0.0
      std: 0.001
    # - outname: actions # this is used for absolute action
    #   type: abs_action_rot_2_6d

sim_env_cfg:
  env: ${preset_robomimic.env}

projection_visualizer_cfg: {}
 
# set the directory where the output files get saved
hydra:
  output_subdir: ${output_dir}/hydra
  run:
    dir: .
